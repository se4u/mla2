Subject of piazza post Submission 2 from xxx
make hw2-e823ab.zip
Write writeup.pdf
all printing must be done as %.13e
estimate parameters of cpd-grid15x15-t100.txt and cpd-grid30x30-t100.txt
syntax is estimate-params network-grid training-grid cpd-grid
test estimate-params by estimate-params test_est_params_network.txt test_est_params_training.txt test_est_params_cpd.txt && diff test_est_params_cpd.txt test_est_params_cpd.txt.gold is empty
alias t=estimate-params test_est_params_network.txt test_est_params_training.txt test_est_params_cpd.txt
I printed out the parameters and then piped to tmp then did a diff to check that I am not missing out any parameters

The total parameters are 31260
diff <(sort test_est_params_cpd.txt) <(sort tmp) | grep "^>" | wc


Question 4.1.4
The code works mainly by counting all the observed variables in their contexts. It is completely contained in estimate_params.py and the estimate-params script is a wrapper on top of the script.
The following call in the source directory produces the required outputs.
./estimate-params f/network-grid15x15-t100.txt f/training-grid15x15-t100.txt cpd-grid15x15-t100.txt
./estimate-params f/network-grid30x30-t100.txt f/training-grid30x30-t100.txt cpd-grid30x30-t100.txt
The main calls are
transition_probs=get_transition_probs_from_the_insane_input_file(training_file_name)
observation_prob=get_observation_prob_from_insane_input_file(training_file_name)

Question 4.1.5
Part 1.
If we dont do parameter sharing then we would have to get counts for a very large number of parameters. As it is the amount of training data that we are usging is quite large to handle on a simple computer. Even if we could get more training data we would not be able to process it in time therefore parameter sharing is important.

Part 2.
We can not model environmental changes, e.g we assume that probability of robot failing to move from row 3 to row 4 is same as movement from row 4 to row 5. Essentially we are assuming that the field is level and that the characteristics of the field like friction, slippage etc. will not vary from row to row.

Part 3.
If we assume that the parameters themeselves have a hyper parameter over them (e.g. the parameters are themselves sampled from the same unimodal beta distribution with a shared beta value). In such a case we could learn potentially differnet values however we would tend to assign them values which are more similar to each other.

Question 4.2
Part 1.

We started by drawing the bayes net and noticed that the Row, Column and Action formed a lattice at the top with the observation being connected only to the row position and column position at that time. We decided to create cliques out of the observations and the row and column positions and 1 clique out of the position row_0, col_0, action_0 and column_1 by addign an edge between row_0 and column_1. We could have created a different clique tree by addign an edge between column_0 and row_1 instead. In that case the sepsets would have contained row_1 instead of col_1 (which is the current sepset)

Part 2 and Part 3.
Running interesection property requires that for any variable, all nodes that contain that variable should be directly connected to each other. We can verify this by looking at the actual clique tree which is of the following form. We can clearly see that none of the variables C_i, R_i, A_i can never occur in disconnected nodes.

(C_0, R_0, A_0, C_1)--------(C_1, R_1, A_1, C_2)-----.........(C_t, R_t, A_t)
 +                          +                                  +
 +--(OWN_0, R_0, C_0)       +--(OWN_1, R_1, C_1)               +--(OWN_t, R_t, C_t)
 +--(OWE_0, R_0, C_0)       +--(OWE_1, R_1, C_1)               +--(OWE_t, R_t, C_t)
 .                          .                                  .
 .                          .                                  .
 +--(OL_l_S_0, R_0, C_0)    +--(OL_l_S_1, R_1, C_1)            +--(OL_l_S_t, R_t, C_t)

 
 Part 4.
 Total number of variables = 4l+4+2+1 but they have different perplexity
 If we simply marginalized over joint CPD then the complexity would be = (2^(4l+4)*M*N*4)^T
 To compute distribution over the final prosition at time T using message passing would require
 QQQ messages
 QQQ Belief updates
 Every message will take QQQ operations
 Every belief update will take QQQ operation

 Part 5.
 QQQ

 Question 4.2.2
 The cliquetree files were generated by running the commands
 python create_cliquetree.py  f/network-grid10x10-t10.txt cliquetree-grid10x10-t10.txt 
 python create_cliquetree.py  f/network-grid10x10-t100.txt cliquetree-grid10x10-t100.txt
 python create_cliquetree.py  f/network-grid10x10-t1000.txt cliquetree-grid10x10-t1000.txt
 python create_cliquetree.py  f/network-grid15x15-t100.txt   cliquetree-grid15x15-t100.txt   
 python create_cliquetree.py  f/network-grid25x25-t100.txt cliquetree-grid25x25-t100.txt
 python create_cliquetree.py  f/network-grid30x30-t100.txt cliquetree-grid30x30-t100.txt
 python create_cliquetree.py  f/network-grid40x40-t100.txt cliquetree-grid40x40-t100.txt

 